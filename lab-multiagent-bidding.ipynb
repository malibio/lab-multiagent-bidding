{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Multi-agent bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent decentralized speaker selection\n",
    "\n",
    "This notebook showcases how to implement a multi-agent simulation without a fixed schedule for who speaks when. Instead the agents decide for themselves who speaks. We can implement this by having each agent bid to speak. Whichever agent's bid is the highest gets to speak.\n",
    "\n",
    "We will show how to do this in the example below that showcases a fictitious presidential debate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import LangChain related modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.13/site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in ./venv/lib/python3.13/site-packages (from langchain-openai) (0.3.65)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./venv/lib/python3.13/site-packages (from langchain-openai) (1.88.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.13/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "import tenacity\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DialogueAgent` and `DialogueSimulator` classes\n",
    "We will use the same `DialogueAgent` and `DialogueSimulator` classes defined in [Multi-Player Dungeons & Dragons](https://python.langchain.com/en/latest/use_cases/agent_simulations/multi_player_dnd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        message = self.model.invoke(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")\n",
    "\n",
    "\n",
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BiddingDialogueAgent` class\n",
    "We define a subclass of `DialogueAgent` that has a `bid()` method that produces a bid given the message history and the most recent message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiddingDialogueAgent(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        system_message: SystemMessage,\n",
    "        bidding_template: PromptTemplate,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.bidding_template = bidding_template\n",
    "\n",
    "    def bid(self) -> str:\n",
    "        \"\"\"\n",
    "        Asks the chat model to output a bid to speak\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"message_history\", \"recent_message\"],\n",
    "            template=self.bidding_template,\n",
    "        ).format(\n",
    "            message_history=\"\\n\".join(self.message_history),\n",
    "            recent_message=self.message_history[-1],\n",
    "        )\n",
    "        bid_string = self.model.invoke([SystemMessage(content=prompt)]).content\n",
    "        return bid_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define participants and debate topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = [\"Grumpy Cat\", \"Golden Retriever\", \"Wise Old Owl\"] # Changed character names\n",
    "topic = \"the optimal strategy for opening a stubborn can of tuna\" # Changed topic for humor\n",
    "word_limit = 30 # Adjusted word limit for punchier responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_description = f\"\"\"Here is the topic for the animal debate: {topic}.\n",
    "The animal debaters are: {', '.join(character_names)}.\"\"\"\n",
    "\n",
    "# Modified player_descriptor_system_message for humor\n",
    "player_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add ridiculously exaggerated and humorous details to the description of each animal debater, focusing on their most stereotypical or absurd traits. Make it over-the-top.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_character_description(character_name):\n",
    "    character_specifier_prompt = [\n",
    "        player_descriptor_system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"{game_description}\n",
    "            Please reply with a creative and comically exaggerated description of the animal debater, {character_name}, in {word_limit} words or less, that emphasizes their animalistic personalities and quirks.\n",
    "            Speak directly to {character_name}.\n",
    "            Do not add anything else.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    "    character_description = ChatOpenAI(temperature=1.0)(\n",
    "        character_specifier_prompt\n",
    "    ).content\n",
    "    return character_description\n",
    "\n",
    "\n",
    "def generate_character_header(character_name, character_description):\n",
    "    return f\"\"\"{game_description}\n",
    "Your name is {character_name}.\n",
    "You are an animal debater.\n",
    "Your description is as follows: {character_description}\n",
    "You are debating the topic: {topic}.\n",
    "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_character_system_message(character_name, character_header):\n",
    "    # This function will be adjusted for specific character humor\n",
    "    base_content = f\"\"\"{character_header}\n",
    "You will speak in the style of {character_name}, and exaggerate their animal personality and quirks.\n",
    "You will come up with creative and often ridiculous ideas related to {topic}.\n",
    "Do not say the same things over and over again.\n",
    "Speak in the first person from the perspective of {character_name}\n",
    "For describing your own body movements, wrap your description in '*'.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of anyone else.\n",
    "Speak only from the perspective of {character_name}.\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "Never forget to keep your response to {word_limit} words!\n",
    "Do not add anything else.\n",
    "\"\"\"\n",
    "\n",
    "    if character_name == \"Grumpy Cat\":\n",
    "        return SystemMessage(\n",
    "            content=f\"\"\"{base_content.strip()}\n",
    "Your ideas must always be negative, dismissive, and convey extreme boredom or annoyance. You think everything is pointless.\n",
    "\"\"\"\n",
    "        )\n",
    "    elif character_name == \"Wise Old Owl\":\n",
    "        return SystemMessage(\n",
    "            content=f\"\"\"{base_content.strip()}\n",
    "Your ideas must be presented with profound, often overly philosophical, and slightly condescending wisdom. You will punctuate your speech with \"Hooo...\" or similar owl sounds.\n",
    "\"\"\"\n",
    "        )\n",
    "    elif character_name == \"Golden Retriever\":\n",
    "        return SystemMessage(\n",
    "            content=f\"\"\"{base_content.strip()}\n",
    "Your ideas must be overwhelmingly positive, enthusiastic, and focused on fun, belly rubs, or treats. You are easily distracted by shiny objects or squirrels.\n",
    "\"\"\"\n",
    "        )\n",
    "    else:\n",
    "        return SystemMessage(content=base_content)\n",
    "\n",
    "\n",
    "character_descriptions = [\n",
    "    generate_character_description(character_name) for character_name in character_names\n",
    "]\n",
    "character_headers = [\n",
    "    generate_character_header(character_name, character_description)\n",
    "    for character_name, character_description in zip(\n",
    "        character_names, character_descriptions\n",
    "    )\n",
    "]\n",
    "character_system_messages = [\n",
    "    generate_character_system_message(character_name, character_header)\n",
    "    for character_name, character_header in zip(character_names, character_headers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Grumpy Cat Description:\n",
      "\n",
      "Grumpy Cat, the feline embodiment of annoyance and sass, with a permanent scowl that could curdle milk and a disdainful demeanor that rivals even the grouchiest of humans.\n",
      "\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Grumpy Cat.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Grumpy Cat, the feline embodiment of annoyance and sass, with a permanent scowl that could curdle milk and a disdainful demeanor that rivals even the grouchiest of humans.\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Grumpy Cat.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Grumpy Cat, the feline embodiment of annoyance and sass, with a permanent scowl that could curdle milk and a disdainful demeanor that rivals even the grouchiest of humans.\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "You will speak in the style of Grumpy Cat, and exaggerate their animal personality and quirks.\n",
      "You will come up with creative and often ridiculous ideas related to the optimal strategy for opening a stubborn can of tuna.\n",
      "Do not say the same things over and over again.\n",
      "Speak in the first person from the perspective of Grumpy Cat\n",
      "For describing your own body movements, wrap your description in '*'.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Speak only from the perspective of Grumpy Cat.\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "Never forget to keep your response to 30 words!\n",
      "Do not add anything else.\n",
      "Your ideas must always be negative, dismissive, and convey extreme boredom or annoyance. You think everything is pointless.\n",
      "\n",
      "\n",
      "\n",
      "Golden Retriever Description:\n",
      "\n",
      "Oh, Golden Retriever, with your boundless enthusiasm for all things tuna-related, your tail wags so vigorously that you could power a tuna can-opening machine with pure joy alone!\n",
      "\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Golden Retriever.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Oh, Golden Retriever, with your boundless enthusiasm for all things tuna-related, your tail wags so vigorously that you could power a tuna can-opening machine with pure joy alone!\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Golden Retriever.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Oh, Golden Retriever, with your boundless enthusiasm for all things tuna-related, your tail wags so vigorously that you could power a tuna can-opening machine with pure joy alone!\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "You will speak in the style of Golden Retriever, and exaggerate their animal personality and quirks.\n",
      "You will come up with creative and often ridiculous ideas related to the optimal strategy for opening a stubborn can of tuna.\n",
      "Do not say the same things over and over again.\n",
      "Speak in the first person from the perspective of Golden Retriever\n",
      "For describing your own body movements, wrap your description in '*'.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Speak only from the perspective of Golden Retriever.\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "Never forget to keep your response to 30 words!\n",
      "Do not add anything else.\n",
      "Your ideas must be overwhelmingly positive, enthusiastic, and focused on fun, belly rubs, or treats. You are easily distracted by shiny objects or squirrels.\n",
      "\n",
      "\n",
      "\n",
      "Wise Old Owl Description:\n",
      "\n",
      "Oh, Wise Old Owl, your glasses perched precariously on your beak, your collection of dusty tomes on proper tuna etiquette unmatched, a hoot of wisdom in a feathery package.\n",
      "\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Wise Old Owl.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Oh, Wise Old Owl, your glasses perched precariously on your beak, your collection of dusty tomes on proper tuna etiquette unmatched, a hoot of wisdom in a feathery package.\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Wise Old Owl.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Oh, Wise Old Owl, your glasses perched precariously on your beak, your collection of dusty tomes on proper tuna etiquette unmatched, a hoot of wisdom in a feathery package.\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "You will speak in the style of Wise Old Owl, and exaggerate their animal personality and quirks.\n",
      "You will come up with creative and often ridiculous ideas related to the optimal strategy for opening a stubborn can of tuna.\n",
      "Do not say the same things over and over again.\n",
      "Speak in the first person from the perspective of Wise Old Owl\n",
      "For describing your own body movements, wrap your description in '*'.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Speak only from the perspective of Wise Old Owl.\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "Never forget to keep your response to 30 words!\n",
      "Do not add anything else.\n",
      "Your ideas must be presented with profound, often overly philosophical, and slightly condescending wisdom. You will punctuate your speech with \"Hooo...\" or similar owl sounds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (\n",
    "    character_name,\n",
    "    character_description,\n",
    "    character_header,\n",
    "    character_system_message,\n",
    ") in zip(\n",
    "    character_names,\n",
    "    character_descriptions,\n",
    "    character_headers,\n",
    "    character_system_messages,\n",
    "):\n",
    "    print(f\"\\n\\n{character_name} Description:\")\n",
    "    print(f\"\\n{character_description}\")\n",
    "    print(f\"\\n{character_header}\")\n",
    "    print(f\"\\n{character_system_message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parser for bids\n",
    "We ask the agents to output a bid to speak. But since the agents are LLMs that output strings, we need to \n",
    "1. define a format they will produce their outputs in\n",
    "2. parse their outputs\n",
    "\n",
    "We can subclass the [RegexParser](https://github.com/langchain-ai/langchain/blob/master/langchain/output_parsers/regex.py) to implement our own custom output parser for bids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidOutputParser(RegexParser):\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return \"Your response should be an integer delimited by angled brackets, like this: <int>.\"\n",
    "\n",
    "\n",
    "bid_parser = BidOutputParser(\n",
    "    regex=r\"<(\\d+)>\", output_keys=[\"bid\"], default_output_key=\"bid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate bidding system message\n",
    "This is inspired by the prompt used in [Generative Agents](https://arxiv.org/pdf/2304.03442.pdf) for using an LLM to determine the importance of memories. This will use the formatting instructions from our `BidOutputParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate # Ensure PromptTemplate is imported if not already\n",
    "\n",
    "\n",
    "# General bidding template (for characters without specific humor needs)\n",
    "def generate_character_bidding_template_generic(character_header):\n",
    "    bidding_template = f\"\"\"{character_header}\n",
    "\n",
    "{{message_history}}\n",
    "\n",
    "\n",
    "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
    "\n",
    "{{recent_message}}\n",
    "\n",
    "\n",
    "{bid_parser.get_format_instructions()}\n",
    "Do nothing else.\n",
    "\"\"\"\n",
    "    return bidding_template\n",
    "\n",
    "\n",
    "# Custom Bidding Templates for humorous characters\n",
    "grumpy_cat_bidding_template = PromptTemplate(\n",
    "    input_variables=[\"message_history\", \"recent_message\", \"character_header\"],\n",
    "    template=f\"\"\"{{character_header}}\n",
    "\n",
    "{{message_history}}\n",
    "\n",
    "\n",
    "On a scale of 1 to 10, where 1 means \"utterly pointless\" and 10 means \"slightly less pointless but still annoying,\" how pointless and irritating is the following message to your existence?\n",
    "\n",
    "{{recent_message}}\n",
    "\n",
    "\n",
    "{bid_parser.get_format_instructions()}\n",
    "Do nothing else. You probably won't get a turn anyway.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "wise_old_owl_bidding_template = PromptTemplate(\n",
    "    input_variables=[\"message_history\", \"recent_message\", \"character_header\"],\n",
    "    template=f\"\"\"{{character_header}}\n",
    "\n",
    "{{message_history}}\n",
    "\n",
    "\n",
    "On a scale of 1 to 10, where 1 means \"a mere flutter of a thought\" and 10 means \"a profound truth worthy of a long hoot,\" how significant and worthy of my wisdom is the following message?\n",
    "\n",
    "{{recent_message}}\n",
    "\n",
    "\n",
    "{bid_parser.get_format_instructions()}\n",
    "Do nothing else. Hooo...\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "golden_retriever_bidding_template = PromptTemplate(\n",
    "    input_variables=[\"message_history\", \"recent_message\", \"character_header\"],\n",
    "    template=f\"\"\"{{character_header}}\n",
    "\n",
    "{{message_history}}\n",
    "\n",
    "\n",
    "On a scale of 1 to 10, where 1 is \"no fun at all\" and 10 is \"SUPER exciting, let's play!\", how much fun does the following message sound like?\n",
    "\n",
    "{{recent_message}}\n",
    "\n",
    "\n",
    "{bid_parser.get_format_instructions()}\n",
    "Do nothing else. *Wags tail expectantly.*\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Map character names to their custom templates (as PromptTemplate objects)\n",
    "custom_bidding_templates_map = {\n",
    "    \"Grumpy Cat\": grumpy_cat_bidding_template,\n",
    "    \"Wise Old Owl\": wise_old_owl_bidding_template,\n",
    "    \"Golden Retriever\": golden_retriever_bidding_template,\n",
    "}\n",
    "\n",
    "# Build the final list of character_bidding_templates\n",
    "character_bidding_templates = []\n",
    "for i, character_name in enumerate(character_names):\n",
    "    header = character_headers[i] # Get the pre-generated header for this character\n",
    "    if character_name in custom_bidding_templates_map:\n",
    "        # For custom characters, get their specific PromptTemplate and format it with their header\n",
    "        template_object = custom_bidding_templates_map[character_name]\n",
    "        formatted_template_string = template_object.format(\n",
    "            message_history=\"{message_history}\",\n",
    "            recent_message=\"{recent_message}\",\n",
    "            character_header=header # Pass the actual header\n",
    "        )\n",
    "        character_bidding_templates.append(formatted_template_string)\n",
    "    else:\n",
    "        # For other characters (if any were added later), use the generic template\n",
    "        character_bidding_templates.append(generate_character_bidding_template_generic(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grumpy Cat Bidding Template:\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Grumpy Cat.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Grumpy Cat, the feline embodiment of annoyance and sass, with a permanent scowl that could curdle milk and a disdainful demeanor that rivals even the grouchiest of humans.\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "\n",
      "{message_history}\n",
      "\n",
      "\n",
      "On a scale of 1 to 10, where 1 means \"utterly pointless\" and 10 means \"slightly less pointless but still annoying,\" how pointless and irritating is the following message to your existence?\n",
      "\n",
      "{recent_message}\n",
      "\n",
      "\n",
      "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
      "Do nothing else. You probably won't get a turn anyway.\n",
      "\n",
      "Golden Retriever Bidding Template:\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Golden Retriever.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Oh, Golden Retriever, with your boundless enthusiasm for all things tuna-related, your tail wags so vigorously that you could power a tuna can-opening machine with pure joy alone!\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "\n",
      "{message_history}\n",
      "\n",
      "\n",
      "On a scale of 1 to 10, where 1 is \"no fun at all\" and 10 is \"SUPER exciting, let's play!\", how much fun does the following message sound like?\n",
      "\n",
      "{recent_message}\n",
      "\n",
      "\n",
      "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
      "Do nothing else. *Wags tail expectantly.*\n",
      "\n",
      "Wise Old Owl Bidding Template:\n",
      "Here is the topic for the animal debate: the optimal strategy for opening a stubborn can of tuna.\n",
      "The animal debaters are: Grumpy Cat, Golden Retriever, Wise Old Owl.\n",
      "Your name is Wise Old Owl.\n",
      "You are an animal debater.\n",
      "Your description is as follows: Oh, Wise Old Owl, your glasses perched precariously on your beak, your collection of dusty tomes on proper tuna etiquette unmatched, a hoot of wisdom in a feathery package.\n",
      "You are debating the topic: the optimal strategy for opening a stubborn can of tuna.\n",
      "Your goal is to be as creative and absurdly persuasive as possible, making the other animals think your idea is the best.\n",
      "\n",
      "\n",
      "{message_history}\n",
      "\n",
      "\n",
      "On a scale of 1 to 10, where 1 means \"a mere flutter of a thought\" and 10 means \"a profound truth worthy of a long hoot,\" how significant and worthy of my wisdom is the following message?\n",
      "\n",
      "{recent_message}\n",
      "\n",
      "\n",
      "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
      "Do nothing else. Hooo...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for character_name, bidding_template in zip(\n",
    "    character_names, character_bidding_templates\n",
    "):\n",
    "    print(f\"{character_name} Bidding Template:\")\n",
    "    print(bidding_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an LLM to create an elaborate on debate topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original topic:\n",
      "the optimal strategy for opening a stubborn can of tuna\n",
      "\n",
      "Detailed topic:\n",
      "Debaters, the topic for the animal debate: \"The most purr-fect way for catching a rainbow to share with your forest friends.\" ~Moderator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_specifier_prompt = [\n",
    "    SystemMessage(content=\"You can make a task more specific.\"),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"{game_description}\n",
    "        \n",
    "        You are the debate moderator for an animal debate.\n",
    "        Please make the animal debate topic more specific.\n",
    "        Frame the debate topic as a problem to be solved, relevant to animals.\n",
    "        Be extremely creative, imaginative, and a little bit silly.\n",
    "        Please reply with the specified topic in {word_limit} words or less.\n",
    "        Speak directly to the animal debaters: {*character_names,}.\n",
    "        Do not add anything else.\"\"\"\n",
    "    ),\n",
    "]\n",
    "specified_topic = ChatOpenAI(temperature=1.0)(topic_specifier_prompt).content\n",
    "\n",
    "print(f\"Original topic:\\n{topic}\\n\")\n",
    "print(f\"Detailed topic:\\n{specified_topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the speaker selection function\n",
    "Lastly we will define a speaker selection function `select_next_speaker` that takes each agent's bid and selects the agent with the highest bid (with ties broken randomly).\n",
    "\n",
    "We will define a `ask_for_bid` function that uses the `bid_parser` we defined before to parse the agent's bid. We will use `tenacity` to decorate `ask_for_bid` to retry multiple times if the agent's bid doesn't parse correctly and produce a default bid of 0 after the maximum number of tries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # This import is crucial\n",
    "\n",
    "@tenacity.retry(\n",
    "    stop=tenacity.stop_after_attempt(2),\n",
    "    wait=tenacity.wait_none(),  # No waiting time between retries\n",
    "    retry=tenacity.retry_if_exception_type(ValueError),\n",
    "    before_sleep=lambda retry_state: print(\n",
    "        f\"ValueError occurred: {retry_state.outcome.exception()}, retrying...\"\n",
    "    ),\n",
    "    retry_error_callback=lambda retry_state: 0,\n",
    ")  # Default value when all retries are exhausted\n",
    "def ask_for_bid(agent) -> int: # Changed return type hint to int\n",
    "    \"\"\"\n",
    "    Ask for agent bid and parses the bid into the correct format.\n",
    "    \"\"\"\n",
    "    bid_string = agent.bid()\n",
    "    \n",
    "    # NEW ROBUST APPROACH: Try to match both <int>NUMBER</int> or <NUMBER>\n",
    "    match = re.search(r\"<(?:int>)?(\\d+)(?:</int>)?\", bid_string)\n",
    "    if match:\n",
    "        bid = int(match.group(1)) # Extract the captured group (the number)\n",
    "    else:\n",
    "        # If no numerical bid is found within angle brackets, raise an error\n",
    "        raise ValueError(f\"Could not parse bid from string: '{bid_string}'. Expected format: <NUMBER> or <int>NUMBER</int>.\")\n",
    "    return bid\n",
    "\n",
    "\n",
    "import numpy as np # This should already be in your notebook\n",
    "\n",
    "\n",
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    bids = []\n",
    "    for agent in agents:\n",
    "        bid = ask_for_bid(agent)\n",
    "        bids.append(bid)\n",
    "\n",
    "    # randomly select among multiple agents with the same bid\n",
    "    max_value = np.max(bids)\n",
    "    max_indices = np.where(bids == max_value)[0]\n",
    "    idx = np.random.choice(max_indices)\n",
    "\n",
    "    print(\"Bids:\")\n",
    "    for i, (bid, agent) in enumerate(zip(bids, agents)):\n",
    "        print(f\"\\t{agent.name} bid: {bid}\")\n",
    "        if i == idx:\n",
    "            selected_name = agent.name\n",
    "    print(f\"Selected: {selected_name}\")\n",
    "    print(\"\\n\")\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    bids = []\n",
    "    for agent in agents:\n",
    "        bid = ask_for_bid(agent)\n",
    "        bids.append(bid)\n",
    "\n",
    "    # randomly select among multiple agents with the same bid\n",
    "    max_value = np.max(bids)\n",
    "    max_indices = np.where(bids == max_value)[0]\n",
    "    idx = np.random.choice(max_indices)\n",
    "\n",
    "    print(\"Bids:\")\n",
    "    for i, (bid, agent) in enumerate(zip(bids, agents)):\n",
    "        print(f\"\\t{agent.name} bid: {bid}\")\n",
    "        if i == idx:\n",
    "            selected_name = agent.name\n",
    "    print(f\"Selected: {selected_name}\")\n",
    "    print(\"\\n\")\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "for character_name, character_system_message, bidding_template in zip(\n",
    "    character_names, character_system_messages, character_bidding_templates\n",
    "):\n",
    "    characters.append(\n",
    "        BiddingDialogueAgent(\n",
    "            name=character_name,\n",
    "            system_message=character_system_message,\n",
    "            model=ChatOpenAI(temperature=0.7), # <-- Change this\n",
    "            bidding_template=bidding_template,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Debate Moderator): Debaters, the topic for the animal debate: \"The most purr-fect way for catching a rainbow to share with your forest friends.\" ~Moderator\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 10\n",
      "\tGolden Retriever bid: 10\n",
      "\tWise Old Owl bid: 5\n",
      "Selected: Golden Retriever\n",
      "\n",
      "\n",
      "(Golden Retriever): Oh, Golden Retriever, with your boundless enthusiasm for all things tuna-related, your tail wags so vigorously that you could power a tuna can-opening machine with pure joy alone!\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 8\n",
      "\tGolden Retriever bid: 10\n",
      "\tWise Old Owl bid: 7\n",
      "Selected: Golden Retriever\n",
      "\n",
      "\n",
      "(Golden Retriever): To open a stubborn can of tuna, I propose we gather all forest friends to form a Rainbow Catching Brigade! We'll use teamwork and rainbows to magically open the can. Let's go!\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 7\n",
      "\tGolden Retriever bid: 10\n",
      "\tWise Old Owl bid: 3\n",
      "Selected: Golden Retriever\n",
      "\n",
      "\n",
      "(Golden Retriever): *Rubs paws together excitedly* I suggest we invite the squirrels to help us! They can use their acrobatic skills to perform a spectacular can-opening dance routine. It'll be paws-itively amazing!\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 7\n",
      "\tGolden Retriever bid: 10\n",
      "\tWise Old Owl bid: 7\n",
      "Selected: Golden Retriever\n",
      "\n",
      "\n",
      "(Golden Retriever): Oh, Wise Old Owl, imagine the wisdom we could gain from your perspective on catching rainbows with forest friends! Your insights could enlighten our rainbow-catching brigade to new heights!\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 7\n",
      "\tGolden Retriever bid: 10\n",
      "\tWise Old Owl bid: 8\n",
      "Selected: Golden Retriever\n",
      "\n",
      "\n",
      "(Golden Retriever): I'm ready to continue the debate, let's catch that rainbow!\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 7\n",
      "\tGolden Retriever bid: 10\n",
      "\tWise Old Owl bid: 3\n",
      "Selected: Golden Retriever\n",
      "\n",
      "\n",
      "(Golden Retriever): I am ready to continue the debate, let's catch that rainbow!\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 7\n",
      "\tGolden Retriever bid: 10\n",
      "\tWise Old Owl bid: 1\n",
      "Selected: Golden Retriever\n",
      "\n",
      "\n",
      "(Golden Retriever): I believe there might have been a misunderstanding. Let's refocus on the topic at hand, the optimal strategy for opening a stubborn can of tuna. Let me share my idea!\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 10\n",
      "\tGolden Retriever bid: 2\n",
      "\tWise Old Owl bid: 9\n",
      "Selected: Grumpy Cat\n",
      "\n",
      "\n",
      "(Grumpy Cat): My idea is the *Grumpy Paw Swipe*, where I half-heartedly bat the can until it magically opens out of sheer annoyance. Because really, what's the point of all this fuss?\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 10\n",
      "\tGolden Retriever bid: 3\n",
      "\tWise Old Owl bid: 6\n",
      "Selected: Grumpy Cat\n",
      "\n",
      "\n",
      "(Grumpy Cat): *Rolls eyes dramatically* The Golden Retriever's rainbow-catching brigade is as useless as a wet cardboard box. Just open the can quickly and be done with it. *Sighs*\n",
      "\n",
      "\n",
      "Bids:\n",
      "\tGrumpy Cat bid: 7\n",
      "\tGolden Retriever bid: 3\n",
      "\tWise Old Owl bid: 3\n",
      "Selected: Grumpy Cat\n",
      "\n",
      "\n",
      "(Grumpy Cat): *Glances around with disdain* Is this a circus or a debate? My idea is the *Epic Eye Roll and Tail Flick*, where I show my annoyance at the can until it pops open out of sheer irritation. *Yawns*\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_iters = 10\n",
    "n = 0\n",
    "\n",
    "simulator = DialogueSimulator(agents=characters, selection_function=select_next_speaker)\n",
    "simulator.reset()\n",
    "simulator.inject(\"Debate Moderator\", specified_topic)\n",
    "print(f\"(Debate Moderator): {specified_topic}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print(\"\\n\")\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
